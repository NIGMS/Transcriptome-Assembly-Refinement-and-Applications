{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ea1e55-d687-4189-b90f-5ce35b3c89de",
   "metadata": {},
   "source": [
    "# MDIBL Transcriptome Assembly Learning Module\n",
    "# Notebook 3: Using TransPi to Performing an \"Annotation Only\" Run\n",
    "\n",
    "## Overview\n",
    "\n",
    "In the previous notebook, we ran the entire default TransPi workflow, generating a small transcriptome from a test data set. While that is a valid exercise in carrying through the workflow, the downstream steps (annotation and assessment) will be unrealistic in their output, since the test set will only generate a few hundred transcripts. In contrast, a more complete estimate of a vertebrate transcriptome will contain tens to hundreds of thousands of transcripts.\n",
    "\n",
    "In this notebook, we will start from an assembled transcriptome. We will work with a more realistic example that was generated and submitted to the NCBI Transcriptome Shotgun Assembly archive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4cd172",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "1. **Understanding the TransPi workflow and its components:** The notebook builds upon previous knowledge of TransPi, focusing on the annotation stage, separating it from the assembly process.  It reinforces the understanding of the overall workflow and its different stages.\n",
    "\n",
    "2. **Performing an \"annotation-only\" run with TransPi:** The primary objective is to learn how to execute TransPi, specifically utilizing the `--onlyAnn` option to process a pre-assembled transcriptome. This teaches efficient use of the tool and avoids unnecessary recomputation.\n",
    "\n",
    "3. **Working with realistic transcriptome data:** The notebook shifts from a small test dataset to a larger, more realistic transcriptome from the NCBI Transcriptome Shotgun Assembly archive. This exposes learners to the scale and characteristics of real-world transcriptome data.\n",
    "\n",
    "4. **Using command-line tools for data manipulation:**  The notebook uses `grep`, `perl` one-liners, and `docker` commands to count sequences, modify configuration files, and manage containerized applications. This improves proficiency in using these essential bioinformatics tools.\n",
    "\n",
    "5. **Interpreting TransPi output:**  Learners analyze the `RUN_INFO.txt` file and other output files to understand the analysis parameters and results. This develops skills in interpreting computational biology results.\n",
    "\n",
    "6. **Understanding and using containerization (Docker):** The notebook introduces the concept of Docker containers and demonstrates how to utilize a BUSCO container to run the BUSCO analysis, highlighting the benefits of containerization for reproducibility and dependency management.  This teaches practical application of containers in bioinformatics.\n",
    "\n",
    "7. **Running BUSCO analysis:** Learners execute BUSCO, a crucial tool for assessing the completeness of transcriptome assemblies. This extends their skillset to include running and interpreting BUSCO results.\n",
    "\n",
    "8. **Interpreting BUSCO and other annotation results:**  The notebook includes checkpoints that challenge learners to interpret the BUSCO results, GO stats, and TransDecoder stats, fostering critical thinking and data interpretation skills.\n",
    "\n",
    "9. **Critical evaluation of data sources:** The notebook encourages learners to consider the source and context of the transcriptome data used, prompting reflection on data quality and limitations.  This emphasizes responsible use of biological data.\n",
    "\n",
    "10. **Independent BUSCO analysis:**  The final checkpoint task requires learners to independently run a BUSCO analysis on a new transcriptome, selecting a data source and lineage, and interpreting the results. This assesses the understanding and practical application of the concepts covered in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04994736",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* **Nextflow:** The core workflow engine used to manage the TransPi pipeline.\n",
    "* **Perl:** Used for a one-liner to modify the Nextflow configuration file.\n",
    "* **Docker:** Used to run BUSCO in a containerized environment.\n",
    "* **BUSCO:** The Benchmarking Universal Single-Copy Orthologs program for assessing genome completeness.\n",
    "* **TransPi:**  The specific transcriptome assembly pipeline.  The notebook assumes this is pre-installed or available through Nextflow.\n",
    "* **Command-line tools:** Basic Unix command-line utilities like `grep`, `ls`, `cat`, `pwd`, etc., are used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16adea33",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81dff4-64b8-42ca-91b5-6ad4cef392ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the command below to watch the video\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('AGuUHmSobEA', width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4cd97f-fc62-40ab-badc-ba0bc6f092e4",
   "metadata": {},
   "source": [
    "> <img src=\"images/AnnotationProcess.png\" width=\"800\">\n",
    ">\n",
    "> **Figure 1:** Annotation workflow for a new, unannotated transcriptome. \n",
    "\n",
    "**Step 1:** Make sure that we start back at the following local working directory: `/home/jupyter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a48fca-ab66-4b62-8a33-d8104dffe1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157e9a9-3457-40cc-9405-91903564d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f6b740-f02c-4993-b082-8cb58fc46e7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Note: </b>  The Transcriptome\n",
    "</div>\n",
    "\n",
    "> The transcriptome that we are using has already been downloaded onto your local directory. It lives within the `resources` directory in the sub-directory named `trans`. It is in the file format `.fa`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755b541-007b-4773-a53e-f01eee1ed570",
   "metadata": {},
   "source": [
    "**Step 2:** Count the sequences in this file.\n",
    "\n",
    "> You should get a count of 31,176."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db05d70-513c-4ef4-92d6-8253562b43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -c \">\" ./resources/trans/Oncorhynchus_mykiss_GGBN01.1.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065fc1a-0a64-447c-8628-b20d5277dd3b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Note: </b>  What is the Oncorhynchus mykiss?\n",
    "</div>\n",
    "\n",
    "> The Oncorhynchus mykiss is commonly known as the **Rainbow Trout**. Here is what they look like:\n",
    ">\n",
    "> <img src=\"images/rainbowTrout.jpeg\"  width=\"500\" >\n",
    "> \n",
    ">> Image Source: https://www.ndow.org/species/rainbow-trout/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d2315-3cdd-4a5c-b58b-6f5621d53abf",
   "metadata": {},
   "source": [
    "**Step 3:** Using a Perl one-liner, we will change the output directory so that the results from the `--all` run in Submodule 02 do not get overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2061d9d-c85a-49a0-b06d-7ecd95fb5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl -i.allloc -pe 's/basicRun/onlyAnnRun/g' ./TransPi/nextflow.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb26ca2-329a-4416-97c4-190a0759790c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Note: </b>  Perl\n",
    "</div>\n",
    "\n",
    "> <img src=\"images/perl-logo.png\" width=\"500\">\n",
    ">\n",
    ">> Image Source: https://medium.com/@aman_adastra/techspace-what-is-perl-1e29a430676c\n",
    ">\n",
    ">**Mini History Lesson on Perl**\n",
    ">\n",
    ">So what is `Perl`? Surprisingly, there is no original acronym for the name, however, some have retroactively given this one: *Practical Extraction and Reporting Language*. It has aspects of many different programming languages and has a broad variety of applications. It was created as a text manipulation language by an expert in linguistics: Larry Wall. Interestingly, Larry Wall became a linguistic expert not to create a programming language but rather as a project to develop a written language for an exclusively oral language in Africa.\n",
    ">\n",
    ">**Comprehending the Perl one-liner**\n",
    ">```python\n",
    "!perl -i.allloc -pe 's/basicRun/onlyAnnRun/g' ./TransPi/nextflow.config\n",
    ">```\n",
    ">- `!`: This indicates that the line is to be executed as a command line argument. \n",
    ">- `perl`: This indicates that the argument is in the Perl programming language.\n",
    ">- `-i.allloc`: This indicates that Perl should edit the input file and create a backup of this file with the added `.allloc` extension.\n",
    ">- `-pe`: These are actually two separate options...\n",
    "    - `-p`: This indicates that each line in the file is to be interpreted independently and printed after it has been processed. \n",
    "    - `-e`: This indicates that the Perl command is to be executed. \n",
    ">- `'s/basicRun/onlyAnnRun/g'`: This is the meat of the Perl one-liner. It is essentially a search and replace.\n",
    "    - It searches for all occurrences of the string `basicRun`, and replaces it with the string `onlyAnnRun`.\n",
    ">- `./TransPi/nextflow.config`: This points to the location of the input file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1541b9-abb6-47c0-aa49-5c1720680376",
   "metadata": {},
   "source": [
    "**Step 4:** Now we can run TransPi using the option `--onlyAnn` which assumes that the transcriptome has been generated, and will only run the various steps for annotation of the transcripts.\n",
    "\n",
    ">This run should take about **29 minutes**, assuming an N1 high-memory, 16 processor 104GB instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb702b3-0a36-4a32-aca5-50dc75f9d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "!NXF_VER=22.10.1 ./nextflow run ./TransPi/TransPi.nf \\\n",
    "-profile docker --onlyAnn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f8dfb-366d-4e0f-af4e-d96f6ee97d34",
   "metadata": {},
   "source": [
    "**Step 5:** As with the basic assembly example of the last workbook, the output will be arranged in a directory structure that is automatically created by Nextflow. Let's get a listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a199f-f19b-42a8-b63d-ca2a4b8e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ./onlyAnnRun/output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3255502-270c-4ebb-9f72-141c4fab5c0f",
   "metadata": {},
   "source": [
    "**Step 6:** Let's take a look at the `RUN_INFO.txt` file to see what the parameters and programs associated with our analysis were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14265d6-bd68-4f08-a55e-c472c3f23faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./onlyAnnRun/output/RUN_INFO.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187a790-276c-4bf2-8ce8-2f7985e8c662",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <i class=\"fa fa-hand-paper-o\" aria-hidden=\"true\"></i>\n",
    "    <b>Note: </b>  Containers\n",
    "</div>\n",
    "\n",
    ">Note that while the \"onlyAnn\" run carries out the searches against Pfam and the BLAS analysis against known proteins, it does not carry out the BUSCO analysis. We can make that happen ourselves however, to do so, we need to learn a little bit about running programs from containers.\n",
    ">\n",
    ">Container systems (and associated images) are one approach that simplifies the use of a broad set of programs, such as is commonly found in the wide field of computational biology. To put it concisely, most programs are not \"stand-alone\" but instead rely upon at least a few supporting libraries or auxiliary programs.  Since many analyses require multiple programs, installation of the necessary programs will also require installation of the supporting components, and critically *sometimes the supporting components of one program conflict with those of other programs.* \n",
    ">\n",
    ">Container systems ([Docker](https://www.docker.com/) and [Singularity](https://sylabs.io/singularity/) are the two most well-known examples) address this by installing and encapsulating the program and all of its necessary supporting components in an image. Each program is then executed in the context of its container image, which is activated just long enough to run its program.\n",
    ">\n",
    ">Because of the way that we have run the TransPi workflow in the previous, our system will already have several container images installed. We can now work directly with these images.\n",
    "\n",
    "**Step 7:** Start by getting a listing of the images that are currently loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888742e-67f9-4f42-8a22-ee3314e9bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2fed5f-0d41-4fc3-8a7c-2600e2993490",
   "metadata": {},
   "source": [
    "**Step 8:** Activate the BUSCO container.\n",
    ">We want the Docker image that contains the program (and all necessary infrastructure) for running the BUSCO analysis. The name is in the first column, but we also need the version number, which is in the second column. So let's put that together and first activate the container and ask it to run BUSCO and just give us back the help message.\n",
    ">\n",
    ">We will use the `docker run` command, and we will use the following options with it:\n",
    ">- `-it`, which means run interactively\n",
    ">- `--rm`, which means clean up after shutting down\n",
    ">- `--volume /home:/home` This is critical because, by default, a Docker image can only see the file system inside of the container image. We need to have it see our working directory, so we create a volume mapping. For simplicity, we will just map the /home directory outside the container to the same address inside. This will let us access and use all of the files that are below `/home`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9539e-5f1f-4590-9b1b-1a20231acd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:5.4.3--pyhdfd78af_0 busco --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282b861-9616-4c07-98cf-bbe0b96747c1",
   "metadata": {},
   "source": [
    "**Step 9:** Run BUSCO (in the container)\n",
    ">Now we will fill out a complete command and ask BUSCO to analyze the same trout data that we just used above. Here is the full command needed to make this run go. A lot is going on here:\n",
    ">\n",
    ">- `-i /home/jupyter/resources/trans/Oncorhynchus_mykiss_GGBN01.1.fa`: this points to the location and name of the file to be examined.\n",
    ">- `-l vertebrata_odb10`: this tells BUSCO to use the vertebrata gene set (genes common to vertebrates) as the target.\n",
    ">- `-o GGBN01_busco_vertebrata`: this tells BUSCO to use this as the label for the output.\n",
    ">- `--out_path /home/jupyter/buscoOutput`: this tells BUSCO where to put the output directory. \n",
    ">- `-m tran`: this tells BUSCO that the inputs are transcripts (rather than protein or genomic data). \n",
    ">- `-c 14`: this tells BUSCO to use 14 CPUs\n",
    ">\n",
    "> This should take about **22 minutes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d3a6b-6d07-4483-8a57-6d795c4eb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the command below to watch the video\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('D95mFnIjRo4', width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82296cfb-cddb-4325-a8a6-ab3eea8fdfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numthreads=!lscpu | grep '^CPU(s)'| awk '{print $2-1}'\n",
    "THREADS = int(numthreads[0])\n",
    "!echo $THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d031c6-6a25-46fc-b041-e69e92fdb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:5.4.3--pyhdfd78af_0 busco \\\n",
    "-i /home/jupyter/resources/trans/Oncorhynchus_mykiss_GGBN01.1.fa \\\n",
    "-l vertebrata_odb10 -o GGBN01_busco_vertebrata \\\n",
    "--out_path /home/jupyter/buscoOutput -m tran -c $THREADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3d8cb-2cb2-4522-89b6-4f102ad4658f",
   "metadata": {},
   "source": [
    "**Step 10:** Look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbb15e-b08b-48a6-8acc-f450fc98152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./buscoOutput/GGBN01_busco_vertebrata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9da3fe-ca2c-41f7-9af9-7384c5688a47",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <i class=\"fa fa-pencil\" aria-hidden=\"true\"></i>\n",
    "    <b>Checkpoint 1:</b> Interpret The Results \n",
    "</div>\n",
    "\n",
    "> Consider the following result files:\n",
    "> - The BUSCO result `./buscoOutput/GGBN01_busco_vertebrata/short_summary.specific.vertebrata_odb10.GGBN01_busco_vertebrata.txt`\n",
    "> - The GO stats result `./onlyAnnRun/output/stats/Oncorhynchus_mykiss_GGBN01.sum_GO.txt`\n",
    "> - The TransDecoder stats result: `./onlyAnnRun/output/stats/Oncorhynchus_mykiss_GGBN01.sum_transdecoder.txt`\n",
    "\n",
    "*The green cards below are interactive. Spend some time to consider the question and click on the card to check your answer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721adc8-08ff-4b35-b994-1d18e61e7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupytercards import display_flashcards\n",
    "display_flashcards('Transcriptome-Assembly-Refinement-and-Applications/quiz-material/03-cp1-1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028ed80-7227-49ee-b4e1-c123ae5bdfda",
   "metadata": {},
   "source": [
    "> Now let's take a look at where the data came from... Consider the abstract of the [Al-Tobasel et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4764514/) paper published from this data.\n",
    ">\n",
    ">>*The ENCODE project revealed that ~70% of the human genome is transcribed. While only 1–2% of the RNAs encode for proteins, the rest are non-coding RNAs. Long non-coding RNAs (lncRNAs) form a diverse class of non-coding RNAs that are longer than 200nt. Emerging evidence indicates that lncRNAs play critical roles in various cellular processes including regulation of gene expression. LncRNAs show low levels of gene expression and sequence conservation, which make their computational identification in genomes difficult. In this study, more than two billion Illumina sequence reads were mapped to the genome reference using the TopHat and Cufflinks software. Transcripts shorter than 200nt, with more than 83–100 amino acids ORF, or with significant homologies to the NCBI nr-protein database were removed. In addition, a computational pipeline was used to filter the remaining transcripts based on a protein-coding-score test. Depending on the filtering stringency conditions, between 31,195 and 54,503 lncRNAs were identified, with only 421 matching known lncRNAs in other species. A digital gene expression atlas revealed 2,935 tissue-specific and 3,269 ubiquitously-expressed lncRNAs. This study annotates the lncRNA rainbow trout genome and provides a valuable resource for functional genomics research in salmonids.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654ccf7-de98-443a-9dd2-6563767a4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_flashcards('../quiz-material/03-cp1-2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954beff-d647-4a1c-9b21-ad05e4fa16c3",
   "metadata": {},
   "source": [
    ">**The key takeaway is to always be mindful of the data you are using before performing analysis on it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17554548-3d09-4984-8ebe-4a6b26a744a1",
   "metadata": {},
   "source": [
    "**Step 11:** Now let's try with one of the other transcriptomes that we downloaded from the NCBI Transcriptome Shotgun Assembly archive.\n",
    "> This should take about **30 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684820c8-ee9f-495d-8476-9f25eaa02d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:5.4.3--pyhdfd78af_0 busco \\\n",
    "-i /home/jupyter/resources/trans/Pseudacris_regilla_GAEI01.1.fa \\\n",
    "-l vertebrata_odb10 -o GAEI01_busco_vertebrata \\\n",
    "--out_path /home/jupyter/buscoOutput -m tran -c $THREADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b26cfb-9f5f-45a5-8466-7e94110c480d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <i class=\"fa fa-pencil\" aria-hidden=\"true\"></i>\n",
    "    <b>Checkpoint 2:</b> Your turn to run a BUSCO analysis \n",
    "</div>\n",
    "\n",
    ">For this checkpoint, you will run another BUSCO analysis, however, this time you will write your own execution command. For the transcriptome used, you have two options:\n",
    ">1. Within the directory that we have been using for the previous two BUSCO runs, `./resources/trans`, there is one more assembled transcriptome named `Microcaecilia_dermatophaga_GFOE01.1.fa`.\n",
    ">2. Go onto the NCBI Transcriptome Shotgun Assembly archive, find your own complete, assembled transcriptome, and use that.\n",
    ">    - If you download the file onto your local computer, there is an upload button (up arrow) in the top left of the Jupyter interface where you can upload the file.\n",
    ">    - If the file you have uploaded is zipped, you will need to unzip it using the following commands: (make sure that the file name after the `>` has the `.fa` extension.)\n",
    ">```python\n",
    "        !gzip -d -c ./PATH/TO/FILE.fsa_nt.gz > ./PATH/TO/FILE.1.fa\n",
    "        !rm ./PATH/TO/FILE.fsa_nt.gz\n",
    ">```\n",
    "> Additionally, consider trying a different lineage (`-l` selection). EZlab, the creators of BUSCO, have produced a large selection of lineages to choose from. Each one has a different set of genes that BUSCO looks for. If you decide to try a different lineage, it is recommended to choose a lineage that falls somewhere within the same family. (e.g., Don't choose the `primates_odb10` lineage if you are choosing to use a bullfrog transcriptome.)\n",
    ">```python\n",
    "        # This will be a complete list of the available datasets\n",
    "        !docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:5.4.3--pyhdfd78af_0 busco --list-datasets\n",
    ">```\n",
    "> Feel free to reference the commands for the previous BUSCO runs and the help command we ran earlier if you are stuck. Additionally, feel free to check out the [BUSCO user guide](https://busco.ezlab.org/busco_userguide.html).\n",
    ">\n",
    ">After the run has been complete, consider the following:\n",
    ">1. How did BUSCO perform on this transcriptome? Does the transcriptome appear to be well assembled based on the provided lineage? If the results are not good, consider the possible reasons why? Is it more likely that the transcriptome chosen was not good? Or potentially a poorly chosen lineage? Or maybe something else entirely?\n",
    ">2. What could be a logical biological reason the output says that there are duplicate copies of the same gene?\n",
    ">3. What could be a possible reason for fragmented copies?\n",
    ">4. Why is it that broader lineages such as metazoa have far fewer genes (954) that BUSCO looks for compared to more specific lineages such as mammalia which has far more genes (9226) that BUSCO looks for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a46ef9-5459-4302-9a34-bf92528c9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your BUSCO command here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cfd48a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This Jupyter Notebook demonstrated the \"annotation only\" run of TransPi, utilizing a pre-assembled transcriptome of *Oncorhynchus mykiss* (Rainbow Trout) containing 31,176 transcripts.  By modifying the `nextflow.config` file and leveraging the `--onlyAnn` option, we efficiently performed annotation steps, including Pfam and BLAST analyses, without repeating the assembly process.  Furthermore, the notebook introduced the concept of Docker containers, showcasing their use in executing BUSCO analysis for assessing transcriptome completeness.  The practical application of BUSCO, along with interpretation of the resulting output files (including GO stats and TransDecoder statistics), emphasized the importance of data context and critical evaluation of transcriptome assembly quality.  Finally, the notebook concluded with a hands-on exercise, prompting users to perform their own BUSCO analysis on a different transcriptome, fostering a deeper understanding of the workflow and its applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc80021",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Remember to proceed to the next notebook [`Submodule_04_gls_assembly.ipynb`](Submodule_04_gls_assembly.ipynb) or shut down your instance if you are finished."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
