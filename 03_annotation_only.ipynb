{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ea1e55-d687-4189-b90f-5ce35b3c89de",
   "metadata": {},
   "source": [
    "# Using TransPi to Performing an \"Annotation Only\" Run\n",
    "\n",
    "In the previous notebook, we ran the entire default TransPi workflow, generating a small transcriptome from a test data set.  While that is a valid exercise in carrying through the workflow, the downstream steps (annotation and assessment) will be unrealistic in their output, since the test set will only generate a few hundred transcripts.  In contrast, a more complete estimate of a vertebrate transcriptome will contain tens to hundreds of thousands of transcripts.\n",
    "\n",
    "In this notebook, we will start from an assembled transcriptome.  We will download and work with a more realistic example that was generated and submitted to the NCBI Transcriptome Shotgun Assembly archive.\n",
    "\n",
    "Make sure that we start out in our working directory that we created and worked with in the basic assembly workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a48fca-ab66-4b62-8a33-d8104dffe1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "workdir=subprocess.check_output(\"pwd\").decode(\"utf-8\").rstrip()\n",
    "workdir\n",
    "%cd $workdir/transpi_example/\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d238818-74ae-457b-a77b-d0505ca6dc81",
   "metadata": {},
   "source": [
    "In order to run an annotation-only run, TransPi has some specific requirements.  First, we must create a directory named \"onlyAnn\" in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc3029-1c59-4fa9-935c-8a6889f9ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir onlyAnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365ddcf-b60e-4057-b9f5-cbc0ab311d4d",
   "metadata": {},
   "source": [
    "Make a variable to hold the google storage bucket to retrieve example transcriptomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038f62a-2832-4744-b26d-28dad45efc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbucket=\"gs://nigms-sandbox/nosi-inbremaine-storage\"\n",
    "gbucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c400b9-e28d-41e2-aa27-03ded9d0d5e5",
   "metadata": {},
   "source": [
    "Now, we will go retrieve a few significantly larger assembled transcriptomes (originating from the [NCBI Transcriptome shotgun assembly](https://www.ncbi.nlm.nih.gov/genbank/tsa/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88056e29-ac24-4e99-9b60-c98ad161e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp $gbucket/example_transcriptomes/Oncorhynchus_mykiss_GGBN01.1.fsa_nt.gz ./\n",
    "!gsutil cp $gbucket/example_transcriptomes/Pseudacris_regilla_GAEI01.1.fsa_nt.gz ./\n",
    "!gsutil cp $gbucket/example_transcriptomes/Microcaecilia_dermatophaga_GFOE01.1.fsa_nt.gz ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b86644-8b63-4f97-b0b7-6ca99e571249",
   "metadata": {},
   "source": [
    "TransPi will process any transcriptome assembly that it finds in the \"annOnly\" directory, but the names must end in either \".fa\" or \".fasta\"  The files that we downloaded are gzipped, and also do not end in the right naming, so we will use gzip to decompress them, while redirecting the output into a renamed file within annOnly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bbd99-6c88-4603-b2cb-db72e37e8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d -c ./Oncorhynchus_mykiss_GGBN01.1.fsa_nt.gz > onlyAnn/Oncorhynchus_mykiss_GGBN01.1.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e58d77-1192-4298-9303-734d18201648",
   "metadata": {},
   "source": [
    "count the sequences in this file (you should get 31,176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db05d70-513c-4ef4-92d6-8253562b43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -c \">\" onlyAnn/Oncorhynchus_mykiss_GGBN01.1.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1541b9-abb6-47c0-aa49-5c1720680376",
   "metadata": {},
   "source": [
    "Now we finally will run TransPi using the option \"--onlyAnn\" which assumes that the transcriptome has been generated, and will now run the various steps for annotation of the transcripts.  Note that we choose to put the output into a new directory, so as not to overwrite results from our previous runs.\n",
    "\n",
    "Tnis run should take about 36 minutes, assuming an N1 high-memory, 16 processor 104GB instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765949c-f6d1-4156-b525-c8b5d01bf71a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nextflow run ../TransPi/TransPi.nf -profile docker --onlyAnn --outdir results_onlyAnn -resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f8dfb-366d-4e0f-af4e-d96f6ee97d34",
   "metadata": {
    "tags": []
   },
   "source": [
    "As with the basic assembly example of the last workbook, the output will be arrange in a directory structure that is automatically created by nextflow.  Let's get a listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a199f-f19b-42a8-b63d-ca2a4b8e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l results_onlyAnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3255502-270c-4ebb-9f72-141c4fab5c0f",
   "metadata": {},
   "source": [
    "Let's take a look at the \"RUN_INFO.txt\" file to see what the parameters and programs associated with our analysis were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14265d6-bd68-4f08-a55e-c472c3f23faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat results_onlyAnn/RUN_INFO.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187a790-276c-4bf2-8ce8-2f7985e8c662",
   "metadata": {},
   "source": [
    "Note that while the \"onlyAnn\" run carries out the searches against Pfam and the BLAS analysis against known proteins, it does not carry out the BUSCO analysis.  We can make that happen ourselves however, but in order to do so, we need to learn a little bit about running programs from containers.  \n",
    "\n",
    "Container systems (and associated images) are one approach that simplifies the use of a broad set of programs, such as is commonly found in the wide field of computational biology. To put it concisely, most programs are not \"stand-alone\" but instead rely upon at least a few supporting libraries or auxiliary programs.  Since many analyses require multiple programs, installation of the necessary programs will also require installation of the supporting components, and critically *sometimes the supporting components of one program conflict with those of other programs.*  \n",
    "\n",
    "Container systems ([Docker](https://www.docker.com/) and [Singularity](https://sylabs.io/singularity/) are the two most well-known examples) address this by installing and encapsulating the program and all of its necessary supporting components in an image.  Each program is then executed in the context of its container image, which i activated just long enough to run its program.\n",
    "\n",
    "Because of the way that we have run the TransPi workflow in the previous, our system will already have several container images installed.  We can now work directly with these images.\n",
    "\n",
    "Start by getting a listing of the images that are currently loaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888742e-67f9-4f42-8a22-ee3314e9bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2fed5f-0d41-4fc3-8a7c-2600e2993490",
   "metadata": {},
   "source": [
    "We want the docker image that contains the program (and all necessary infrastructure) for running the BUSCO analysis.  The name is in the first column, but we also need the version number, which is the second column.  So let's put that together and first activate the container and ask it to run busco and just give us back the help message.\n",
    "\n",
    "We will use the docker run command, and we will use the following options with it:\n",
    "- -it, which means run interactively\n",
    "- --rm, which means clean up after shutting down\n",
    "- --volume /home:/home This is critical, because by default, a docker image can only see the file system inside of the container image.  We need to have it see our working directory, so we create a volume mapping.  For simplicity, we will just map the /home directory outside the container to the same address inside.  This will let us access and use all of the files that are below /home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9539e-5f1f-4590-9b1b-1a20231acd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:4.1.4--py_2 busco --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282b861-9616-4c07-98cf-bbe0b96747c1",
   "metadata": {},
   "source": [
    "Now that we have that, we will fill out a complete command and ask busco to analyze the same data as above (the trout dataset that is currently in the \"onlyAnn\" subdirectory), and put the output in a new directory here in our current working directory.  Here is the full command needed to make this run go.  There is a lot going on here,\n",
    "- -i \\$workdir/transpi_example/onlyAnn/Oncorhynchus_mykiss_GGBN01.1.fa => this tells the location and name of the file to be examined\n",
    "- -l \\$workdir/TransPi/DBs/busco_db/vertebrata_odb10 => this tells busco to use the vertebrata gene set (genes common to vertebrates) as the target\n",
    "- -o GGBN01_busco_vertebrata => this tells busco to use this for the label of the output  \n",
    "- --out_path /home/jupyter/transpi_example => this tells busco to put the output in the current directory\n",
    "- -m tran => this tells busco that the input is transcripts (rather than protein or genomic data) \n",
    "- -c 14 => this tells busco to use 14 cpus\n",
    "- --offline => this tells busco not to try to download updated versions of the target gene set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d031c6-6a25-46fc-b041-e69e92fdb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:4.1.4--py_2 busco\\\n",
    "-i $workdir/transpi_example/onlyAnn/Oncorhynchus_mykiss_GGBN01.1.fa \\\n",
    "-l $workdir/TransPi/DBs/busco_db/vertebrata_odb10 -o GGBN01_busco_vertebrata \\\n",
    "--out_path $workdir/transpi_example -m tran -c 14 --offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882268b-4afc-4737-8d68-3a7ce05c1e6a",
   "metadata": {},
   "source": [
    "The analysis should take about 12 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbb15e-b08b-48a6-8acc-f450fc98152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls GGBN01_busco_vertebrata/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954beff-d647-4a1c-9b21-ad05e4fa16c3",
   "metadata": {},
   "source": [
    "The output above (with pretty much 0 hits) proves one of the maxims of this kind of work:  ***Know what your data is before you start analyzing it.***\n",
    "\n",
    "The sample in question GGBN01 can be looked up in NCBI TSA, and it explicitly says that it was targeted to long non-coding (lnc) RNA sequences.  Part of the process was to filter out all probable protein coding genes.  As such, most of the annotation tools will fail to find anything.  \n",
    "\n",
    "So let's try instead with one of the other transcriptomes that we downloaded from TSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684820c8-ee9f-495d-8476-9f25eaa02d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm onlyAnn/Oncorhynchus_mykiss_GGBN01.1.fa\n",
    "!gzip -d -c ./Pseudacris_regilla_GAEI01.1.fsa_nt.gz > onlyAnn/Pseudacris_regilla_GAEI01.1.fa\n",
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:4.1.4--py_2 busco \\\n",
    "-i $workdir/transpi_example/onlyAnn/Pseudacris_regilla_GAEI01.1.fa \\\n",
    "-l $workdir/TransPi/DBs/busco_db/vertebrata_odb10 -o GAEI01_busco_vertebrata \\\n",
    "--out_path $workdir/transpi_example -m tran -c 14 --offline -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993ee8d-d286-4c81-a598-1baad0688e81",
   "metadata": {},
   "source": [
    "This run should take about 20 minutes to complete.\n",
    "\n",
    "Finally for one more illustrative comparison, let's run the third analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de215a2-46b7-41ad-a9ea-6e9ad148c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm onlyAnn/Pseudacris_regilla_GAEI01.1.fa\n",
    "!gzip -d -c ./Microcaecilia_dermatophaga_GFOE01.1.fsa_nt.gz > onlyAnn/Microcaecilia_dermatophaga_GFOE01.1.fa\n",
    "!docker run -it --rm --volume /home:/home quay.io/biocontainers/busco:4.1.4--py_2 busco \\\n",
    "-i $workdir/transpi_example/onlyAnn/Microcaecilia_dermatophaga_GFOE01.1.fa \\\n",
    "-l $workdir/TransPi/DBs/busco_db/vertebrata_odb10 -o GFOE01_busco_vertebrata \\\n",
    "--out_path $workdir/transpi_example -m tran -c 14 --offline -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c72d1fb-daf8-438c-96f9-05137d4dd098",
   "metadata": {},
   "source": [
    "This run should take about 33 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4cc4d-4a4d-48d1-989c-1425297fd6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
